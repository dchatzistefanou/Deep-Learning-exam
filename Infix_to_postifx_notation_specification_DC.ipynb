{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Description:\n",
        "\n",
        "The purpose of this project is to implement a neural network that performs the translation of mathematical formulae from traditional **infix notation**—where the operator appears between two operands—to **postfix** (also known as Reverse Polish Notation), where the operator follows the operands.\n",
        "\n",
        "Infix notation is the most commonly used in human-readable mathematics (e.g., a + b), but it is inherently ambiguous without additional syntactic aids such as parentheses or operator precedence rules. This ambiguity arises because different parse trees can correspond to the same expression depending on how operations are grouped.\n",
        "\n",
        "In contrast, postfix notation eliminates the need for parentheses entirely. The order of operations is explicitly encoded by the position of the operators relative to the operands, making it more suitable for stack-based evaluation and easier to parse programmatically.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Consider the ambiguous infix expression:\n",
        "a + b * c\n",
        "\n",
        "This expression can be parsed in at least two different ways:\n",
        "\n",
        "Interpretation (Infix):\t(a + b) * c\t   \n",
        "Equivalent Postfix: ab+c*\n",
        "\n",
        "Interpretation (Infix):\ta + (b * c)\t          \n",
        "Equivalent Postfix: abc*+\n",
        "\n",
        "\n",
        "This project aims to learn such disambiguations and generate the correct postfix form from a given infix expression using a data-driven approach based on neural networks.\n",
        "\n",
        "To simplify the task and control the complexity of expressions, we restrict our dataset to formulae with a maximum syntactic depth of 4. This means that the abstract syntax trees representing these expressions will have at most three levels, ensuring that the neural network operates on a bounded and manageable set of possible structures."
      ],
      "metadata": {
        "id": "uPFPtHankgU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "i_tRkF6n6smU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "DwmBl5qs2eWm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We build formulae using 6 identifiers a,b,c,d,e,f and 4 binary operators +,-,*,/.\n",
        "For simplicity we do not take advantage of precedence or associativity rules for infix notation, and suppose that all binary operations as always fully parenthesizes: (e1 op e2)."
      ],
      "metadata": {
        "id": "QFSHpEHjpa1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Constants --------------------\n",
        "OPERATORS = ['+', '-', '*', '/']\n",
        "IDENTIFIERS = list('abcdef')\n",
        "SPECIAL_TOKENS = ['PAD', 'SOS', 'EOS']\n",
        "SYMBOLS = ['(', ')', '+', '-', '*', '/']\n",
        "VOCAB = SPECIAL_TOKENS + SYMBOLS + IDENTIFIERS + ['JUNK'] #may use junk in autoregressive generation\n",
        "\n",
        "token_to_id = {tok: i for i, tok in enumerate(VOCAB)}\n",
        "id_to_token = {i: tok for tok, i in token_to_id.items()}\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "PAD_ID = token_to_id['PAD']\n",
        "EOS_ID = token_to_id['EOS']\n",
        "SOS_ID = token_to_id['SOS']\n",
        "\n",
        "MAX_DEPTH = 4\n",
        "MAX_LEN = 4*2**MAX_DEPTH -2 #enough to fit expressions at given depth (+ EOS)"
      ],
      "metadata": {
        "id": "IINM81OK61pH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Expression Generation --------------------\n",
        "def generate_infix_expression(max_depth):\n",
        "    if max_depth == 0:\n",
        "        return random.choice(IDENTIFIERS)\n",
        "    elif random.random() < 0.25:\n",
        "        return generate_infix_expression(max_depth - 1)\n",
        "    else:\n",
        "        left = generate_infix_expression(max_depth - 1)\n",
        "        right = generate_infix_expression(max_depth - 1)\n",
        "        op = random.choice(OPERATORS)\n",
        "        return f'({left} {op} {right})'\n",
        "\n",
        "def tokenize(expr):\n",
        "    return [c for c in expr if c in token_to_id]\n",
        "\n",
        "def infix_to_postfix(tokens):\n",
        "    precedence = {'+': 1, '-': 1, '*': 2, '/': 2}\n",
        "    output, stack = [], []\n",
        "    for token in tokens:\n",
        "        if token in IDENTIFIERS:\n",
        "            output.append(token)\n",
        "        elif token in OPERATORS:\n",
        "            while stack and stack[-1] in OPERATORS and precedence[stack[-1]] >= precedence[token]:\n",
        "                output.append(stack.pop())\n",
        "            stack.append(token)\n",
        "        elif token == '(':\n",
        "            stack.append(token)\n",
        "        elif token == ')':\n",
        "            while stack and stack[-1] != '(':\n",
        "                output.append(stack.pop())\n",
        "            stack.pop()\n",
        "    while stack:\n",
        "        output.append(stack.pop())\n",
        "    return output\n",
        "\n",
        "def encode(tokens, max_len=MAX_LEN):\n",
        "    ids = [token_to_id[t] for t in tokens] + [EOS_ID]\n",
        "    return ids + [PAD_ID] * (max_len - len(ids))\n",
        "\n",
        "def decode_sequence(token_ids, id_to_token, pad_token='PAD', eos_token='EOS'):\n",
        "    \"\"\"\n",
        "    Converts a list of token IDs into a readable string by decoding tokens.\n",
        "    Stops at the first EOS token if present, and ignores PAD tokens.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    for token_id in token_ids:\n",
        "        token = id_to_token.get(token_id, '?')\n",
        "        if token == eos_token:\n",
        "            break\n",
        "        if token != pad_token:\n",
        "            tokens.append(token)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def generate_dataset(n,max_depth=MAX_DEPTH):\n",
        "    X, Y = [], []\n",
        "    for _ in range(n):\n",
        "        expr = generate_infix_expression(MAX_DEPTH)\n",
        "        #expr = expr_gen.generate(max_depth=max_dthep)\n",
        "        infix = tokenize(expr)\n",
        "        postfix = infix_to_postfix(infix)\n",
        "        X.append(encode(infix))\n",
        "        Y.append(encode(postfix))\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "#you might use the shift function for teacher-forcing\n",
        "def shift_right(seqs):\n",
        "    shifted = np.zeros_like(seqs)\n",
        "    shifted[:, 1:] = seqs[:, :-1]\n",
        "    shifted[:, 0] = SOS_ID\n",
        "    return shifted"
      ],
      "metadata": {
        "id": "T-fO911d6_FW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define a simple dataset, and inspect a few samples. You can use a larger dataset, if you want, or directly use the generator."
      ],
      "metadata": {
        "id": "DENVmP3Jq5Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = generate_dataset(10000)\n",
        "decoder_input_train = shift_right(Y_train)\n",
        "\n",
        "# Dataset\n",
        "X_val, Y_val = generate_dataset(1000)\n",
        "decoder_input_val = shift_right(Y_val)"
      ],
      "metadata": {
        "id": "gdlonKn47dE7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i =  np.random.randint(10000)\n",
        "print(i)\n",
        "print(\"infix : \",decode_sequence(X_train[i],id_to_token))\n",
        "print(\"posfix notation: \",decode_sequence(Y_train[i],id_to_token))\n",
        "print(\"teacher forcing : \", decode_sequence(decoder_input_train[i],id_to_token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TogClrT6F2Th",
        "outputId": "d684afef-f505-4d66-8311-f61ef892a37f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7270\n",
            "infix :  ( ( ( d + f ) / ( ( e + c ) * ( c - e ) ) ) * ( ( ( c * e ) + ( c + d ) ) * ( ( a / d ) / ( f + a ) ) ) )\n",
            "posfix notation:  d f + e c + c e - * / c e * c d + + a d / f a + / * *\n",
            "teacher forcing :  SOS d f + e c + c e - * / c e * c d + + a d / f a + / * *\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constraints\n",
        "* You may use any architecture (decoder-only, encoder-decoder, or other).\n",
        "\n",
        "* The maximum number of parameters is 2 million.\n",
        "\n",
        "* Beam search is not allowed.\n",
        "\n",
        "* You may adapt the formula generator to your needs, but preserve its core logic—especially the frequency distribution of formulas by depth, as it may significantly influence model performance.\n",
        "\n",
        "* You may train your model using a pre-generated fixed dataset (e.g., an array) or directly use an on-the-fly generator.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MgqDkVaztBuv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "RmjjS1uOxUa9",
        "outputId": "87cee998-9c33-4ab9-df1b-5e12bd2a66be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │      \u001b[38;5;34m4,112\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,112</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m796,688\u001b[0m (3.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">796,688</span> (3.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m796,688\u001b[0m (3.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">796,688</span> (3.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total parameters: 796,688\n",
            "Parameter limit: 2,000,000\n",
            "Within limit: True\n"
          ]
        }
      ],
      "source": [
        "# Model hyperparameters\n",
        "EMBEDDING_DIM = 128\n",
        "LSTM_UNITS = 256\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = layers.Input(shape=(None,), name='encoder_inputs')\n",
        "encoder_embedding = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, mask_zero=True)(encoder_inputs)\n",
        "encoder_lstm = layers.LSTM(LSTM_UNITS, return_state=True, dropout=DROPOUT_RATE, name='encoder_lstm')\n",
        "encoder_outputs, encoder_h, encoder_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [encoder_h, encoder_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = layers.Input(shape=(None,), name='decoder_inputs')\n",
        "decoder_embedding = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, mask_zero=True)(decoder_inputs)\n",
        "decoder_lstm = layers.LSTM(LSTM_UNITS, return_sequences=True, return_state=True,\n",
        "                           dropout=DROPOUT_RATE, name='decoder_lstm')\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = layers.Dense(VOCAB_SIZE, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Training model\n",
        "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model summary\n",
        "model.summary()\n",
        "\n",
        "# Let's count parameters\n",
        "total_params = model.count_params()\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "print(f\"Parameter limit: 2,000,000\")\n",
        "print(f\"Within limit: {total_params <= 2000000}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4N8ZMSGjxUa-"
      },
      "outputs": [],
      "source": [
        "#For autoregressive generation\n",
        "encoder_model = models.Model(encoder_inputs, [encoder_h, encoder_c])\n",
        "\n",
        "# Decoder model for inference\n",
        "decoder_state_input_h = layers.Input(shape=(LSTM_UNITS,))\n",
        "decoder_state_input_c = layers.Input(shape=(LSTM_UNITS,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs_inf, decoder_h_inf, decoder_c_inf = decoder_lstm(\n",
        "    decoder_embedding, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states_inf = [decoder_h_inf, decoder_c_inf]\n",
        "decoder_outputs_inf = decoder_dense(decoder_outputs_inf)\n",
        "\n",
        "decoder_model = models.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs_inf] + decoder_states_inf\n",
        ")\n",
        "\n",
        "def autoregressive_decode(model, encoder_input, max_len=MAX_LEN):\n",
        "    \"\"\"\n",
        "    Autoregressively decode the postfix notation from infix input.\n",
        "\n",
        "    This function implements AUTOREGRESSIVE generation:\n",
        "    - Takes ONLY infix notation as input (encoded)\n",
        "    - Generates postfix tokens ONE BY ONE (autoregressively)\n",
        "    - Each token is generated based on previous tokens\n",
        "    - Uses greedy decoding (no beam search)\n",
        "\n",
        "    Args:\n",
        "        model: The trained model (not used directly, but encoder_model and decoder_model are)\n",
        "        encoder_input: Encoded infix sequence (numpy array)\n",
        "        max_len: Maximum length of generated sequence\n",
        "\n",
        "    Returns:\n",
        "        Generated postfix sequence (numpy array of token IDs, starting with SOS)\n",
        "    \"\"\"\n",
        "    encoder_input = np.array(encoder_input)\n",
        "    encoder_input = encoder_input.reshape(1, -1)\n",
        "\n",
        "    # Get encoder states from infix input\n",
        "    encoder_h, encoder_c = encoder_model.predict(encoder_input, verbose=0)\n",
        "\n",
        "    # Initialize decoder state with encoder states\n",
        "    decoder_state = [encoder_h, encoder_c]\n",
        "\n",
        "    # Start with SOS token\n",
        "    decoder_input = np.array([[SOS_ID]])\n",
        "    generated = [SOS_ID]\n",
        "\n",
        "    # AUTOREGRESSIVE GENERATION\n",
        "    for _ in range(max_len - 1):\n",
        "        output_tokens, decoder_h, decoder_c = decoder_model.predict(\n",
        "            [decoder_input] + decoder_state, verbose=0)\n",
        "\n",
        "        # Get the predicted token (greedy decoding - no beam search:) )\n",
        "        predicted_id = np.argmax(output_tokens[0, 0, :])\n",
        "        generated.append(int(predicted_id))\n",
        "\n",
        "        if predicted_id == EOS_ID:\n",
        "            break\n",
        "        decoder_state = [decoder_h, decoder_c]\n",
        "        decoder_input = np.array([[predicted_id]])\n",
        "\n",
        "    return np.array(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYQKIOJpxUa-",
        "outputId": "2a0b3d7b-9d0b-4dcc-af89-c06bdf05cc62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.2775 - loss: 2.0400 - val_accuracy: 0.1799 - val_loss: 1.6333\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.1616 - loss: 1.6234 - val_accuracy: 0.1314 - val_loss: 1.5650\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.1398 - loss: 1.5230 - val_accuracy: 0.1672 - val_loss: 1.2980\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.1822 - loss: 1.2278 - val_accuracy: 0.2336 - val_loss: 0.8667\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2484 - loss: 0.8279 - val_accuracy: 0.3047 - val_loss: 0.5836\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3114 - loss: 0.5800 - val_accuracy: 0.3118 - val_loss: 0.4237\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3292 - loss: 0.4259 - val_accuracy: 0.3837 - val_loss: 0.3678\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3786 - loss: 0.3288 - val_accuracy: 0.3948 - val_loss: 0.2526\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3840 - loss: 0.2561 - val_accuracy: 0.3976 - val_loss: 0.1829\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3914 - loss: 0.1969 - val_accuracy: 0.3708 - val_loss: 0.1466\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3739 - loss: 0.1593 - val_accuracy: 0.3743 - val_loss: 0.1245\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3731 - loss: 0.1341 - val_accuracy: 0.3746 - val_loss: 0.1006\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3716 - loss: 0.1100 - val_accuracy: 0.3651 - val_loss: 0.0877\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.3750 - loss: 0.0939 - val_accuracy: 0.3688 - val_loss: 0.0872\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3731 - loss: 0.0840 - val_accuracy: 0.3636 - val_loss: 0.0666\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3690 - loss: 0.0734 - val_accuracy: 0.3711 - val_loss: 0.0630\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.3730 - loss: 0.0637 - val_accuracy: 0.3741 - val_loss: 0.0558\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3733 - loss: 0.0558 - val_accuracy: 0.3691 - val_loss: 0.0542\n",
            "Epoch 19/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3695 - loss: 0.0489 - val_accuracy: 0.3673 - val_loss: 0.0496\n",
            "Epoch 20/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3694 - loss: 0.0530 - val_accuracy: 0.3782 - val_loss: 0.0526\n",
            "Epoch 21/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3794 - loss: 0.0438 - val_accuracy: 0.3779 - val_loss: 0.0335\n",
            "Epoch 22/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3785 - loss: 0.0330 - val_accuracy: 0.3768 - val_loss: 0.0353\n",
            "Epoch 23/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3768 - loss: 0.0308 - val_accuracy: 0.3748 - val_loss: 0.0365\n",
            "Epoch 24/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3756 - loss: 0.0292 - val_accuracy: 0.3715 - val_loss: 0.0440\n",
            "Epoch 25/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3732 - loss: 0.0296 - val_accuracy: 0.3745 - val_loss: 0.0305\n",
            "Epoch 26/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3758 - loss: 0.0246 - val_accuracy: 0.3736 - val_loss: 0.0326\n",
            "Epoch 27/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3758 - loss: 0.0231 - val_accuracy: 0.3749 - val_loss: 0.0293\n",
            "Epoch 28/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3754 - loss: 0.0225 - val_accuracy: 0.3685 - val_loss: 0.0267\n",
            "Epoch 29/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3714 - loss: 0.0213 - val_accuracy: 0.3719 - val_loss: 0.0301\n",
            "Epoch 30/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3715 - loss: 0.0187 - val_accuracy: 0.3663 - val_loss: 0.0267\n",
            "Epoch 31/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3695 - loss: 0.0195 - val_accuracy: 0.3653 - val_loss: 0.0272\n",
            "Epoch 32/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.3678 - loss: 0.0250 - val_accuracy: 0.3669 - val_loss: 0.0327\n",
            "Epoch 33/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3686 - loss: 0.0207 - val_accuracy: 0.3688 - val_loss: 0.0212\n",
            "Epoch 34/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3700 - loss: 0.0146 - val_accuracy: 0.3736 - val_loss: 0.0143\n",
            "Epoch 35/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.3732 - loss: 0.0109 - val_accuracy: 0.3673 - val_loss: 0.0189\n",
            "Epoch 36/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3709 - loss: 0.0129 - val_accuracy: 0.3690 - val_loss: 0.0232\n",
            "Epoch 37/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3720 - loss: 0.0122 - val_accuracy: 0.3686 - val_loss: 0.0157\n",
            "Epoch 38/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3713 - loss: 0.0113 - val_accuracy: 0.3719 - val_loss: 0.0200\n",
            "Epoch 39/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3735 - loss: 0.0127 - val_accuracy: 0.3689 - val_loss: 0.0153\n",
            "Epoch 40/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3702 - loss: 0.0111 - val_accuracy: 0.3625 - val_loss: 0.0175\n",
            "Epoch 41/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.3659 - loss: 0.0102 - val_accuracy: 0.3663 - val_loss: 0.0167\n",
            "Epoch 42/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3676 - loss: 0.0118 - val_accuracy: 0.3687 - val_loss: 0.0141\n",
            "Epoch 43/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3688 - loss: 0.0089 - val_accuracy: 0.3675 - val_loss: 0.0211\n",
            "Epoch 44/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3731 - loss: 0.0102 - val_accuracy: 0.3720 - val_loss: 0.0174\n",
            "Epoch 45/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3737 - loss: 0.0080 - val_accuracy: 0.3717 - val_loss: 0.0121\n",
            "Epoch 46/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3735 - loss: 0.0078 - val_accuracy: 0.3713 - val_loss: 0.0127\n",
            "Epoch 47/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3728 - loss: 0.0084 - val_accuracy: 0.3636 - val_loss: 0.0151\n",
            "Epoch 48/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3670 - loss: 0.0070 - val_accuracy: 0.3718 - val_loss: 0.0107\n",
            "Epoch 49/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3744 - loss: 0.0059 - val_accuracy: 0.3685 - val_loss: 0.0138\n",
            "Epoch 50/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3697 - loss: 0.0080 - val_accuracy: 0.3622 - val_loss: 0.0179\n",
            "Epoch 51/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3641 - loss: 0.0094 - val_accuracy: 0.3607 - val_loss: 0.0206\n",
            "Epoch 52/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3662 - loss: 0.0097 - val_accuracy: 0.3627 - val_loss: 0.0060\n",
            "Epoch 53/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3685 - loss: 0.0025 - val_accuracy: 0.3670 - val_loss: 0.0048\n",
            "Epoch 54/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3706 - loss: 0.0024 - val_accuracy: 0.3765 - val_loss: 0.0101\n",
            "Epoch 55/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.3781 - loss: 0.0044 - val_accuracy: 0.3837 - val_loss: 0.0089\n",
            "Epoch 56/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3829 - loss: 0.0050 - val_accuracy: 0.3835 - val_loss: 0.0137\n",
            "Epoch 57/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3872 - loss: 0.0086 - val_accuracy: 0.3850 - val_loss: 0.0102\n",
            "Epoch 58/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3894 - loss: 0.0073 - val_accuracy: 0.3896 - val_loss: 0.0110\n",
            "Epoch 59/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3949 - loss: 0.0047 - val_accuracy: 0.4085 - val_loss: 0.0091\n",
            "Epoch 60/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4077 - loss: 0.0038 - val_accuracy: 0.4001 - val_loss: 0.0092\n",
            "Epoch 61/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4001 - loss: 0.0049 - val_accuracy: 0.3924 - val_loss: 0.0157\n",
            "Epoch 62/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4017 - loss: 0.0076 - val_accuracy: 0.4131 - val_loss: 0.0058\n",
            "Epoch 63/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4181 - loss: 0.0033 - val_accuracy: 0.4604 - val_loss: 0.0109\n",
            "Epoch 64/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4558 - loss: 0.0065 - val_accuracy: 0.4461 - val_loss: 0.0072\n",
            "Epoch 65/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4423 - loss: 0.0065 - val_accuracy: 0.4386 - val_loss: 0.0090\n",
            "Epoch 66/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4412 - loss: 0.0040 - val_accuracy: 0.4499 - val_loss: 0.0049\n",
            "Epoch 67/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4578 - loss: 0.0025 - val_accuracy: 0.4728 - val_loss: 0.0094\n",
            "Epoch 68/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4730 - loss: 0.0029 - val_accuracy: 0.4834 - val_loss: 0.0105\n",
            "Epoch 69/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.4630 - loss: 0.0062 - val_accuracy: 0.4654 - val_loss: 0.0081\n",
            "Epoch 70/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4647 - loss: 0.0036 - val_accuracy: 0.4706 - val_loss: 0.0054\n",
            "Epoch 71/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4700 - loss: 0.0027 - val_accuracy: 0.4718 - val_loss: 0.0081\n",
            "Epoch 72/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.4778 - loss: 0.0073 - val_accuracy: 0.4899 - val_loss: 0.0066\n",
            "Epoch 73/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4904 - loss: 0.0033 - val_accuracy: 0.4972 - val_loss: 0.0133\n",
            "Epoch 74/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.4973 - loss: 0.0061 - val_accuracy: 0.5128 - val_loss: 0.0056\n",
            "Epoch 75/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.5043 - loss: 0.0036 - val_accuracy: 0.5042 - val_loss: 0.0051\n",
            "Epoch 76/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4973 - loss: 0.0015 - val_accuracy: 0.5121 - val_loss: 0.0048\n",
            "Epoch 77/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.5007 - loss: 0.0027 - val_accuracy: 0.5101 - val_loss: 0.0068\n",
            "Epoch 78/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4906 - loss: 0.0042 - val_accuracy: 0.4834 - val_loss: 0.0129\n",
            "Epoch 79/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4876 - loss: 0.0045 - val_accuracy: 0.4908 - val_loss: 0.0064\n",
            "Epoch 80/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4851 - loss: 0.0019 - val_accuracy: 0.4749 - val_loss: 0.0043\n",
            "Epoch 81/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4760 - loss: 0.0014 - val_accuracy: 0.4766 - val_loss: 0.0094\n",
            "Epoch 82/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4794 - loss: 0.0057 - val_accuracy: 0.4799 - val_loss: 0.0094\n",
            "Epoch 83/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4943 - loss: 0.0038 - val_accuracy: 0.5079 - val_loss: 0.0039\n",
            "Epoch 84/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5072 - loss: 0.0013 - val_accuracy: 0.5046 - val_loss: 0.0051\n",
            "Epoch 85/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5074 - loss: 0.0015 - val_accuracy: 0.4992 - val_loss: 0.0033\n",
            "Epoch 86/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5010 - loss: 9.6781e-04 - val_accuracy: 0.5145 - val_loss: 0.0037\n",
            "Epoch 87/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5059 - loss: 0.0011 - val_accuracy: 0.5089 - val_loss: 0.0058\n",
            "Epoch 88/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5006 - loss: 0.0070 - val_accuracy: 0.5095 - val_loss: 0.0074\n",
            "Epoch 89/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4989 - loss: 0.0047 - val_accuracy: 0.4854 - val_loss: 0.0046\n",
            "Epoch 90/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4827 - loss: 0.0015 - val_accuracy: 0.4846 - val_loss: 0.0037\n",
            "Epoch 91/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4832 - loss: 7.2711e-04 - val_accuracy: 0.4782 - val_loss: 0.0029\n",
            "Epoch 92/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4852 - loss: 7.5605e-04 - val_accuracy: 0.4708 - val_loss: 0.0029\n",
            "Epoch 93/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4714 - loss: 9.8176e-04 - val_accuracy: 0.4757 - val_loss: 0.0140\n",
            "Epoch 94/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4525 - loss: 0.0092 - val_accuracy: 0.4239 - val_loss: 0.0055\n",
            "Epoch 95/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4354 - loss: 0.0020 - val_accuracy: 0.4384 - val_loss: 0.0028\n",
            "Epoch 96/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4339 - loss: 8.6039e-04 - val_accuracy: 0.4259 - val_loss: 0.0040\n",
            "Epoch 97/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4234 - loss: 0.0022 - val_accuracy: 0.4292 - val_loss: 0.0111\n",
            "Epoch 98/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4363 - loss: 0.0059 - val_accuracy: 0.4378 - val_loss: 0.0048\n",
            "Epoch 99/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4484 - loss: 0.0014 - val_accuracy: 0.4552 - val_loss: 0.0039\n",
            "Epoch 100/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4528 - loss: 0.0012 - val_accuracy: 0.4431 - val_loss: 0.0028\n"
          ]
        }
      ],
      "source": [
        "#Model training\n",
        "Y_train_target = Y_train.reshape(Y_train.shape[0], Y_train.shape[1], 1)\n",
        "Y_val_target = Y_val.reshape(Y_val.shape[0], Y_val.shape[1], 1)\n",
        "\n",
        "# Training configuration\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "DROPOUT_RATE = 0.25\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_train, decoder_input_train],\n",
        "    Y_train_target,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=([X_val, decoder_input_val], Y_val_target),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "We shall evaluate a generated item y_pred using \"prefix accuracy\", the lenght of\n",
        "the initial prefix of y_pred matching the ground true y_true. This will be divided by the maximum length of y_true and y_pred (up to EOS), so that a perfect match has score 1.\n",
        "\n",
        "* It's more informative than exact match (which is often 0)\n",
        "\n",
        "* It’s tighter than edit distance: focuses on generation flow\n",
        "\n",
        "* Captures where the model starts to make errors\n",
        "\n"
      ],
      "metadata": {
        "id": "QDUjK4SGvT0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prefix_accuracy_single(y_true, y_pred, id_to_token, eos_id=EOS_ID, verbose=False):\n",
        "    t_str = decode_sequence(y_true, id_to_token).split(' EOS')[0]\n",
        "    p_str = decode_sequence(y_pred, id_to_token).split(' EOS')[0]\n",
        "    t_tokens = t_str.strip().split()\n",
        "    p_tokens = p_str.strip().split()\n",
        "    print(len(p_tokens))\n",
        "    max_len = max(len(t_tokens), len(p_tokens))\n",
        "    n = min(len(t_tokens), len(p_tokens))\n",
        "    match_len = 0\n",
        "    while match_len < n and t_tokens[match_len] == p_tokens[match_len]:\n",
        "        match_len += 1\n",
        "    score = match_len / max_len if max_len>0 else 0\n",
        "    if verbose:\n",
        "        print(\"TARGET :\", ' '.join(t_tokens))\n",
        "        print(\"PREDICT:\", ' '.join(p_tokens))\n",
        "        print(f\"PREFIX MATCH: {match_len}/{len(t_tokens)} → {score:.2f}\")\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "MeqyasiYxCpU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "i = np.random.randint(10000)\n",
        "expected = np.copy(Y_train[i])\n",
        "generated = np.copy(Y_train[i])\n",
        "expr_len = np.where(generated==EOS_ID)[0][0]\n",
        "j = np.random.randint(expr_len)\n",
        "generated[j] = EOS_ID #making shorter\n",
        "prefix_accuracy_single(expected,generated,id_to_token,verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWX6qvXH7uDz",
        "outputId": "c3a555a9-846c-4032-8b54-4ff358b5bc20"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "TARGET : a e / b a - / e f / d d + + - c b + b - c e + b / / -\n",
            "PREDICT: a e / b a - / e f / d d + +\n",
            "PREFIX MATCH: 14/27 → 0.52\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5185185185185185"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the exam, evaluate you model on a test set of 30 expressions. Repeat this evaluation 10 times, and return the mean and std for this rounds."
      ],
      "metadata": {
        "id": "HeCRiqvsxQax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(no=30,rounds=10):\n",
        "  rscores =[]\n",
        "  for i in range(rounds):\n",
        "    print(\"round=\",i)\n",
        "    X_test, Y_test = generate_dataset(no)\n",
        "    scores = []\n",
        "    for j in range(no):\n",
        "      encoder_input=X_test[j]\n",
        "      generated = autoregressive_decode(model, encoder_input)[1:] #remove SOS\n",
        "      scores.append(prefix_accuracy_single(Y_test[j], generated, id_to_token))\n",
        "    rscores.append(np.mean(scores))\n",
        "  return np.mean(rscores),np.std(rscores)\n",
        "\n",
        "res, std = test(30,10)\n",
        "print(\"score=\",res,\"std=\",std)"
      ],
      "metadata": {
        "id": "aR-9eTs28x4l",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ca1f74-574e-4dbc-b5f8-2b5556a419db"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "round= 0\n",
            "21\n",
            "23\n",
            "13\n",
            "5\n",
            "27\n",
            "19\n",
            "21\n",
            "15\n",
            "17\n",
            "19\n",
            "13\n",
            "27\n",
            "13\n",
            "27\n",
            "23\n",
            "17\n",
            "29\n",
            "23\n",
            "21\n",
            "15\n",
            "23\n",
            "27\n",
            "23\n",
            "19\n",
            "13\n",
            "19\n",
            "17\n",
            "15\n",
            "19\n",
            "11\n",
            "round= 1\n",
            "19\n",
            "15\n",
            "15\n",
            "19\n",
            "25\n",
            "27\n",
            "15\n",
            "13\n",
            "19\n",
            "23\n",
            "25\n",
            "15\n",
            "27\n",
            "7\n",
            "3\n",
            "31\n",
            "15\n",
            "29\n",
            "27\n",
            "13\n",
            "21\n",
            "7\n",
            "3\n",
            "13\n",
            "25\n",
            "27\n",
            "3\n",
            "9\n",
            "23\n",
            "13\n",
            "round= 2\n",
            "29\n",
            "7\n",
            "9\n",
            "11\n",
            "11\n",
            "13\n",
            "7\n",
            "23\n",
            "15\n",
            "27\n",
            "23\n",
            "25\n",
            "7\n",
            "21\n",
            "11\n",
            "27\n",
            "15\n",
            "15\n",
            "17\n",
            "11\n",
            "15\n",
            "23\n",
            "13\n",
            "23\n",
            "21\n",
            "27\n",
            "13\n",
            "13\n",
            "15\n",
            "23\n",
            "round= 3\n",
            "19\n",
            "11\n",
            "21\n",
            "3\n",
            "21\n",
            "9\n",
            "5\n",
            "9\n",
            "11\n",
            "23\n",
            "13\n",
            "15\n",
            "11\n",
            "13\n",
            "11\n",
            "15\n",
            "15\n",
            "17\n",
            "19\n",
            "15\n",
            "21\n",
            "11\n",
            "27\n",
            "7\n",
            "17\n",
            "17\n",
            "15\n",
            "23\n",
            "25\n",
            "27\n",
            "round= 4\n",
            "9\n",
            "9\n",
            "25\n",
            "11\n",
            "27\n",
            "13\n",
            "25\n",
            "29\n",
            "19\n",
            "7\n",
            "29\n",
            "23\n",
            "23\n",
            "19\n",
            "5\n",
            "15\n",
            "19\n",
            "9\n",
            "13\n",
            "15\n",
            "9\n",
            "15\n",
            "21\n",
            "11\n",
            "17\n",
            "15\n",
            "23\n",
            "19\n",
            "7\n",
            "9\n",
            "round= 5\n",
            "25\n",
            "9\n",
            "23\n",
            "13\n",
            "9\n",
            "23\n",
            "3\n",
            "29\n",
            "23\n",
            "15\n",
            "7\n",
            "19\n",
            "17\n",
            "13\n",
            "23\n",
            "15\n",
            "15\n",
            "9\n",
            "13\n",
            "23\n",
            "21\n",
            "15\n",
            "3\n",
            "13\n",
            "23\n",
            "19\n",
            "17\n",
            "27\n",
            "27\n",
            "9\n",
            "round= 6\n",
            "15\n",
            "23\n",
            "27\n",
            "23\n",
            "17\n",
            "5\n",
            "21\n",
            "27\n",
            "5\n",
            "21\n",
            "23\n",
            "15\n",
            "7\n",
            "13\n",
            "1\n",
            "5\n",
            "19\n",
            "29\n",
            "17\n",
            "13\n",
            "15\n",
            "11\n",
            "11\n",
            "21\n",
            "17\n",
            "15\n",
            "11\n",
            "15\n",
            "5\n",
            "9\n",
            "round= 7\n",
            "15\n",
            "9\n",
            "25\n",
            "25\n",
            "23\n",
            "13\n",
            "7\n",
            "7\n",
            "17\n",
            "21\n",
            "9\n",
            "27\n",
            "21\n",
            "25\n",
            "11\n",
            "23\n",
            "15\n",
            "23\n",
            "21\n",
            "19\n",
            "13\n",
            "23\n",
            "27\n",
            "23\n",
            "21\n",
            "15\n",
            "17\n",
            "25\n",
            "5\n",
            "23\n",
            "round= 8\n",
            "3\n",
            "15\n",
            "27\n",
            "7\n",
            "19\n",
            "23\n",
            "15\n",
            "25\n",
            "11\n",
            "19\n",
            "27\n",
            "11\n",
            "13\n",
            "21\n",
            "19\n",
            "15\n",
            "9\n",
            "13\n",
            "7\n",
            "9\n",
            "19\n",
            "19\n",
            "11\n",
            "21\n",
            "27\n",
            "25\n",
            "27\n",
            "21\n",
            "19\n",
            "21\n",
            "round= 9\n",
            "13\n",
            "7\n",
            "11\n",
            "11\n",
            "19\n",
            "9\n",
            "9\n",
            "25\n",
            "13\n",
            "15\n",
            "19\n",
            "23\n",
            "3\n",
            "3\n",
            "19\n",
            "11\n",
            "31\n",
            "11\n",
            "9\n",
            "17\n",
            "13\n",
            "3\n",
            "19\n",
            "13\n",
            "25\n",
            "11\n",
            "15\n",
            "7\n",
            "19\n",
            "17\n",
            "score= 0.995351724137931 std= 0.0059665496415806105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a6758ae",
        "outputId": "d4b18dce-360a-493d-f43e-ded657b4dcb7"
      },
      "source": [
        "model.save_weights('model_weights.weights.h5')\n",
        "print(\"Model weights saved to 'model_weights.weights.h5'\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to 'model_weights.weights.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8005257c"
      },
      "source": [
        "File_id = \"1hclDt8Kzo0b69EYGuIsuL_ffZptk9KK7\""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1hclDt8Kzo0b69EYGuIsuL_ffZptk9KK7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCUMIY05EHBo",
        "outputId": "7196a7ac-ef68-4a3f-e3ff-063a264c8732"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hclDt8Kzo0b69EYGuIsuL_ffZptk9KK7\n",
            "To: /content/model_weights.weights.h5\n",
            "100% 9.60M/9.60M [00:00<00:00, 14.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be sure to evalutate the generator: your model may only take as input the expression in infix format and return its translation to postifix.\n",
        "\n",
        "If you are usuing an encoder-decoder model, generation must be done autoregressively."
      ],
      "metadata": {
        "id": "AxxXPqKQ86fZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What to deliver\n",
        "\n",
        "As usual you are supposed to deliver a single notebook witten in Keras. You are auhtorized to use Keras3 with pytorch as backend if you prefer.\n",
        "\n",
        "Do no upload a zip file: the submission will be rejected.\n",
        "\n",
        "The python notebook should have a clear documentation of the training phase, possibly with its history.\n",
        "\n",
        "Please provide the network parameters by means of gdown."
      ],
      "metadata": {
        "id": "aOBottQI9o1h"
      }
    }
  ]
}